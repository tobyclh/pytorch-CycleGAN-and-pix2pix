{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from options.test_options import TestOptions\n",
    "from data import CreateDataLoader\n",
    "from models import create_model\n",
    "from util.visualizer import Visualizer\n",
    "from util import html\n",
    "import torch\n",
    "from models.cycle_gan_model import CycleGANModel\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------ Options -------------\n",
      "aspect_ratio: 1.0\n",
      "batchSize: 1\n",
      "checkpoints_dir: ./checkpoints\n",
      "dataroot: None\n",
      "dataset_mode: unaligned\n",
      "display_id: 1\n",
      "display_port: 8097\n",
      "display_server: http://localhost\n",
      "display_winsize: 256\n",
      "fineSize: 256\n",
      "gpu_ids: [0]\n",
      "how_many: 50\n",
      "init_type: normal\n",
      "input_nc: 3\n",
      "isTrain: False\n",
      "loadSize: 286\n",
      "max_dataset_size: inf\n",
      "model: cycle_gan\n",
      "nThreads: 4\n",
      "n_layers_D: 3\n",
      "name: experiment_name\n",
      "ndf: 64\n",
      "ngf: 64\n",
      "no_dropout: False\n",
      "no_flip: False\n",
      "norm: instance\n",
      "ntest: inf\n",
      "output_nc: 3\n",
      "phase: test\n",
      "resize_or_crop: resize_and_crop\n",
      "results_dir: ./results/\n",
      "serial_batches: False\n",
      "suffix: \n",
      "verbose: False\n",
      "which_direction: AtoB\n",
      "which_epoch: latest\n",
      "which_model_netD: basic\n",
      "which_model_netG: resnet_9blocks\n",
      "-------------- End ----------------\n",
      "CustomDatasetDataLoader\n",
      "dataset [SingleImageDataset] was created\n",
      "---------- Networks initialized -------------\n",
      "[Network G] Total number of parameters : 11.378 M\n",
      "-----------------------------------------------\n",
      "model [TestModel] was created\n",
      "0000: process image... ['datasets/horse2zebra/testA/n02381460_1000.jpg']\n",
      "0001: process image... ['datasets/horse2zebra/testA/n02381460_1010.jpg']\n",
      "0002: process image... ['datasets/horse2zebra/testA/n02381460_1030.jpg']\n",
      "0003: process image... ['datasets/horse2zebra/testA/n02381460_1090.jpg']\n",
      "0004: process image... ['datasets/horse2zebra/testA/n02381460_1100.jpg']\n",
      "0005: process image... ['datasets/horse2zebra/testA/n02381460_1110.jpg']\n",
      "0006: process image... ['datasets/horse2zebra/testA/n02381460_1120.jpg']\n",
      "0007: process image... ['datasets/horse2zebra/testA/n02381460_1160.jpg']\n",
      "0008: process image... ['datasets/horse2zebra/testA/n02381460_120.jpg']\n",
      "0009: process image... ['datasets/horse2zebra/testA/n02381460_1210.jpg']\n",
      "0010: process image... ['datasets/horse2zebra/testA/n02381460_1260.jpg']\n",
      "0011: process image... ['datasets/horse2zebra/testA/n02381460_1300.jpg']\n",
      "0012: process image... ['datasets/horse2zebra/testA/n02381460_1350.jpg']\n",
      "0013: process image... ['datasets/horse2zebra/testA/n02381460_1360.jpg']\n",
      "0014: process image... ['datasets/horse2zebra/testA/n02381460_140.jpg']\n",
      "0015: process image... ['datasets/horse2zebra/testA/n02381460_1420.jpg']\n",
      "0016: process image... ['datasets/horse2zebra/testA/n02381460_1540.jpg']\n",
      "0017: process image... ['datasets/horse2zebra/testA/n02381460_1620.jpg']\n",
      "0018: process image... ['datasets/horse2zebra/testA/n02381460_1630.jpg']\n",
      "0019: process image... ['datasets/horse2zebra/testA/n02381460_1660.jpg']\n",
      "0020: process image... ['datasets/horse2zebra/testA/n02381460_1690.jpg']\n",
      "0021: process image... ['datasets/horse2zebra/testA/n02381460_1740.jpg']\n",
      "0022: process image... ['datasets/horse2zebra/testA/n02381460_1750.jpg']\n",
      "0023: process image... ['datasets/horse2zebra/testA/n02381460_180.jpg']\n",
      "0024: process image... ['datasets/horse2zebra/testA/n02381460_1820.jpg']\n",
      "0025: process image... ['datasets/horse2zebra/testA/n02381460_1830.jpg']\n",
      "0026: process image... ['datasets/horse2zebra/testA/n02381460_1870.jpg']\n",
      "0027: process image... ['datasets/horse2zebra/testA/n02381460_1920.jpg']\n",
      "0028: process image... ['datasets/horse2zebra/testA/n02381460_20.jpg']\n",
      "0029: process image... ['datasets/horse2zebra/testA/n02381460_200.jpg']\n",
      "0030: process image... ['datasets/horse2zebra/testA/n02381460_2050.jpg']\n",
      "0031: process image... ['datasets/horse2zebra/testA/n02381460_2100.jpg']\n",
      "0032: process image... ['datasets/horse2zebra/testA/n02381460_2120.jpg']\n",
      "0033: process image... ['datasets/horse2zebra/testA/n02381460_2150.jpg']\n",
      "0034: process image... ['datasets/horse2zebra/testA/n02381460_2280.jpg']\n",
      "0035: process image... ['datasets/horse2zebra/testA/n02381460_2460.jpg']\n",
      "0036: process image... ['datasets/horse2zebra/testA/n02381460_2540.jpg']\n",
      "0037: process image... ['datasets/horse2zebra/testA/n02381460_2580.jpg']\n",
      "0038: process image... ['datasets/horse2zebra/testA/n02381460_2650.jpg']\n",
      "0039: process image... ['datasets/horse2zebra/testA/n02381460_2710.jpg']\n",
      "0040: process image... ['datasets/horse2zebra/testA/n02381460_2870.jpg']\n",
      "0041: process image... ['datasets/horse2zebra/testA/n02381460_2890.jpg']\n",
      "0042: process image... ['datasets/horse2zebra/testA/n02381460_2940.jpg']\n",
      "0043: process image... ['datasets/horse2zebra/testA/n02381460_2950.jpg']\n",
      "0044: process image... ['datasets/horse2zebra/testA/n02381460_3010.jpg']\n",
      "0045: process image... ['datasets/horse2zebra/testA/n02381460_3040.jpg']\n",
      "0046: process image... ['datasets/horse2zebra/testA/n02381460_3110.jpg']\n",
      "0047: process image... ['datasets/horse2zebra/testA/n02381460_3120.jpg']\n",
      "0048: process image... ['datasets/horse2zebra/testA/n02381460_3240.jpg']\n",
      "0049: process image... ['datasets/horse2zebra/testA/n02381460_3330.jpg']\n"
     ]
    }
   ],
   "source": [
    "opt = TestOptions().parse()\n",
    "opt.dataroot = 'datasets/horse2zebra/testA'\n",
    "opt.checkpoints_dir = './checkpoints/'\n",
    "opt.name = 'horse2zebra_pretrained'\n",
    "opt.no_dropout = True\n",
    "opt.model = 'test'\n",
    "opt.dataset_mode = 'single'\n",
    "opt.loadSize = 256\n",
    "opt.nThreads = 1   # test code only supports nThreads = 1\n",
    "opt.batchSize = 1  # test code only supports batchSize = 1\n",
    "opt.serial_batches = True  # no shuffle\n",
    "opt.no_flip = True  # no flip\n",
    "opt.display_id = -1  # no visdom display\n",
    "data_loader = CreateDataLoader(opt)\n",
    "dataset = data_loader.load_data()\n",
    "model = create_model(opt)\n",
    "visualizer = Visualizer(opt)\n",
    "# create website\n",
    "web_dir = os.path.join(opt.results_dir, opt.name, '%s_%s' % (opt.phase, opt.which_epoch))\n",
    "webpage = html.HTML(web_dir, 'Experiment = %s, Phase = %s, Epoch = %s' % (opt.name, opt.phase, opt.which_epoch))\n",
    "# test\n",
    "for i, data in enumerate(dataset):\n",
    "    if i >= opt.how_many:\n",
    "        break\n",
    "    model.set_input(data)\n",
    "    model.test()\n",
    "    visuals = model.get_current_visuals()\n",
    "    img_path = model.get_image_paths()\n",
    "    print('%04d: process image... %s' % (i, img_path))\n",
    "    visualizer.save_images(webpage, visuals, img_path, aspect_ratio=opt.aspect_ratio)\n",
    "\n",
    "webpage.save()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResnetGenerator(\n",
       "  (down): Sequential(\n",
       "    (0): ReflectionPad2d((3, 3, 3, 3))\n",
       "    (1): Conv2d(3, 64, kernel_size=(7, 7), stride=(1, 1))\n",
       "    (2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False)\n",
       "    (3): ReLU(inplace)\n",
       "    (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (5): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False)\n",
       "    (6): ReLU(inplace)\n",
       "    (7): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (8): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False)\n",
       "    (9): ReLU(inplace)\n",
       "  )\n",
       "  (up): Sequential(\n",
       "    (0): ResnetBlock(\n",
       "      (conv_block): Sequential(\n",
       "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False)\n",
       "        (3): ReLU(inplace)\n",
       "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False)\n",
       "      )\n",
       "    )\n",
       "    (1): ResnetBlock(\n",
       "      (conv_block): Sequential(\n",
       "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False)\n",
       "        (3): ReLU(inplace)\n",
       "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False)\n",
       "      )\n",
       "    )\n",
       "    (2): ResnetBlock(\n",
       "      (conv_block): Sequential(\n",
       "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False)\n",
       "        (3): ReLU(inplace)\n",
       "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False)\n",
       "      )\n",
       "    )\n",
       "    (3): ResnetBlock(\n",
       "      (conv_block): Sequential(\n",
       "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False)\n",
       "        (3): ReLU(inplace)\n",
       "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False)\n",
       "      )\n",
       "    )\n",
       "    (4): ResnetBlock(\n",
       "      (conv_block): Sequential(\n",
       "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False)\n",
       "        (3): ReLU(inplace)\n",
       "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False)\n",
       "      )\n",
       "    )\n",
       "    (5): ResnetBlock(\n",
       "      (conv_block): Sequential(\n",
       "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False)\n",
       "        (3): ReLU(inplace)\n",
       "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False)\n",
       "      )\n",
       "    )\n",
       "    (6): ResnetBlock(\n",
       "      (conv_block): Sequential(\n",
       "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False)\n",
       "        (3): ReLU(inplace)\n",
       "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False)\n",
       "      )\n",
       "    )\n",
       "    (7): ResnetBlock(\n",
       "      (conv_block): Sequential(\n",
       "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False)\n",
       "        (3): ReLU(inplace)\n",
       "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False)\n",
       "      )\n",
       "    )\n",
       "    (8): ResnetBlock(\n",
       "      (conv_block): Sequential(\n",
       "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False)\n",
       "        (3): ReLU(inplace)\n",
       "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
       "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False)\n",
       "      )\n",
       "    )\n",
       "    (9): ConvTranspose2d(256, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "    (10): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False)\n",
       "    (11): ReLU(inplace)\n",
       "    (12): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "    (13): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False)\n",
       "    (14): ReLU(inplace)\n",
       "    (15): ReflectionPad2d((3, 3, 3, 3))\n",
       "    (16): Conv2d(64, 3, kernel_size=(7, 7), stride=(1, 1))\n",
       "    (17): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model.netG.module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dick = torch.load('/home/toby/Documents/pytorch-CycleGAN-and-pix2pix/checkpoints/horse2zebra_pretrained/latest_net_G.pth')\n",
    "#for key, value in dick.items():\n",
    "#    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: 'down'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-1c830259db70>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mnew_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'module.up'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mnew_key\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m'.'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0mnew_key\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m'.'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: 'down'"
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "new_dict = OrderedDict()\n",
    "for key, value in dick.items():\n",
    "    names = key.split('.')\n",
    "    if len(names) == 3 and int(names[1]) < 10:\n",
    "        new_key = 'module.' + key.replace('model', 'down')\n",
    "    else:\n",
    "        new_key = 'module.up'\n",
    "        new_key += '.' + str(int(names[1]) - 10)\n",
    "        for name in names[2:]:\n",
    "            new_key += '.' + name\n",
    "    new_dict[new_key] = value\n",
    "    #print(new_key)\n",
    "#torch.save(new_dict, './checkpoints/horse2zebra_pretrained/updated_net_G.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for k in model.netG.state_dict().keys():\n",
    "#    print(k)\n",
    "model.netG.load_state_dict(new_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0000: process image... ['datasets/horse2zebra/testA/n02381460_1000.jpg']\n",
      "0001: process image... ['datasets/horse2zebra/testA/n02381460_1010.jpg']\n",
      "0002: process image... ['datasets/horse2zebra/testA/n02381460_1030.jpg']\n",
      "0003: process image... ['datasets/horse2zebra/testA/n02381460_1090.jpg']\n",
      "0004: process image... ['datasets/horse2zebra/testA/n02381460_1100.jpg']\n",
      "0005: process image... ['datasets/horse2zebra/testA/n02381460_1110.jpg']\n",
      "0006: process image... ['datasets/horse2zebra/testA/n02381460_1120.jpg']\n",
      "0007: process image... ['datasets/horse2zebra/testA/n02381460_1160.jpg']\n",
      "0008: process image... ['datasets/horse2zebra/testA/n02381460_120.jpg']\n",
      "0009: process image... ['datasets/horse2zebra/testA/n02381460_1210.jpg']\n",
      "0010: process image... ['datasets/horse2zebra/testA/n02381460_1260.jpg']\n",
      "0011: process image... ['datasets/horse2zebra/testA/n02381460_1300.jpg']\n",
      "0012: process image... ['datasets/horse2zebra/testA/n02381460_1350.jpg']\n",
      "0013: process image... ['datasets/horse2zebra/testA/n02381460_1360.jpg']\n",
      "0014: process image... ['datasets/horse2zebra/testA/n02381460_140.jpg']\n",
      "0015: process image... ['datasets/horse2zebra/testA/n02381460_1420.jpg']\n",
      "0016: process image... ['datasets/horse2zebra/testA/n02381460_1540.jpg']\n",
      "0017: process image... ['datasets/horse2zebra/testA/n02381460_1620.jpg']\n",
      "0018: process image... ['datasets/horse2zebra/testA/n02381460_1630.jpg']\n",
      "0019: process image... ['datasets/horse2zebra/testA/n02381460_1660.jpg']\n",
      "0020: process image... ['datasets/horse2zebra/testA/n02381460_1690.jpg']\n",
      "0021: process image... ['datasets/horse2zebra/testA/n02381460_1740.jpg']\n",
      "0022: process image... ['datasets/horse2zebra/testA/n02381460_1750.jpg']\n",
      "0023: process image... ['datasets/horse2zebra/testA/n02381460_180.jpg']\n",
      "0024: process image... ['datasets/horse2zebra/testA/n02381460_1820.jpg']\n",
      "0025: process image... ['datasets/horse2zebra/testA/n02381460_1830.jpg']\n",
      "0026: process image... ['datasets/horse2zebra/testA/n02381460_1870.jpg']\n",
      "0027: process image... ['datasets/horse2zebra/testA/n02381460_1920.jpg']\n",
      "0028: process image... ['datasets/horse2zebra/testA/n02381460_20.jpg']\n",
      "0029: process image... ['datasets/horse2zebra/testA/n02381460_200.jpg']\n",
      "0030: process image... ['datasets/horse2zebra/testA/n02381460_2050.jpg']\n",
      "0031: process image... ['datasets/horse2zebra/testA/n02381460_2100.jpg']\n",
      "0032: process image... ['datasets/horse2zebra/testA/n02381460_2120.jpg']\n",
      "0033: process image... ['datasets/horse2zebra/testA/n02381460_2150.jpg']\n",
      "0034: process image... ['datasets/horse2zebra/testA/n02381460_2280.jpg']\n",
      "0035: process image... ['datasets/horse2zebra/testA/n02381460_2460.jpg']\n",
      "0036: process image... ['datasets/horse2zebra/testA/n02381460_2540.jpg']\n",
      "0037: process image... ['datasets/horse2zebra/testA/n02381460_2580.jpg']\n",
      "0038: process image... ['datasets/horse2zebra/testA/n02381460_2650.jpg']\n",
      "0039: process image... ['datasets/horse2zebra/testA/n02381460_2710.jpg']\n",
      "0040: process image... ['datasets/horse2zebra/testA/n02381460_2870.jpg']\n",
      "0041: process image... ['datasets/horse2zebra/testA/n02381460_2890.jpg']\n",
      "0042: process image... ['datasets/horse2zebra/testA/n02381460_2940.jpg']\n",
      "0043: process image... ['datasets/horse2zebra/testA/n02381460_2950.jpg']\n",
      "0044: process image... ['datasets/horse2zebra/testA/n02381460_3010.jpg']\n",
      "0045: process image... ['datasets/horse2zebra/testA/n02381460_3040.jpg']\n",
      "0046: process image... ['datasets/horse2zebra/testA/n02381460_3110.jpg']\n",
      "0047: process image... ['datasets/horse2zebra/testA/n02381460_3120.jpg']\n",
      "0048: process image... ['datasets/horse2zebra/testA/n02381460_3240.jpg']\n",
      "0049: process image... ['datasets/horse2zebra/testA/n02381460_3330.jpg']\n"
     ]
    }
   ],
   "source": [
    "for i, data in enumerate(dataset):\n",
    "    if i >= opt.how_many:\n",
    "        break\n",
    "    print()\n",
    "    model.set_input(data)\n",
    "    model.test()\n",
    "    visuals = model.get_current_visuals()\n",
    "    img_path = model.get_image_paths()\n",
    "    #print('%04d: process image... %s' % (i, img_path))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.3.1.post2'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_iter = iter(data_loader)\n",
    "data = next(data_iter)\n",
    "#model.netG(data)\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
